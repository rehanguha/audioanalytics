<template>
  <div>
    <h2>Waveplot</h2>
    <p>
In performance, musicians convert sheet music representations into sound which is transmitted through the air as air pressure oscillations. In essence, sound is simply air vibrating (Wikipedia). Sound vibrates through the air as longitudinal waves, i.e. the oscillations are parallel to the direction of propagation.
Audio refers to the production, transmission, or reception of sounds that are audible by humans. An audio signal is a representation of sound that represents the fluctuation in air pressure caused by the vibration as a function of time. Unlike sheet music or symbolic representations, audio representations encode everything that is necessary to reproduce an acoustic realization of a piece of music. However, note parameters such as onsets, durations, and pitches are not encoded explicitly. This makes converting from an audio representation to a symbolic representation a difficult and ill-defined task.

      The change in air pressure at a certain time is graphically represented by a pressure-time plot, or simply waveform.
    </p>
    <img v-bind:src="wave_image" />
    <hr>
    <h2>Spectrogram</h2>
    <p>
      A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called sonographs, voiceprints, or voicegrams. When the data is represented in a 3D plot they may be called waterfalls.
      Spectrograms are used extensively in the fields of music, linguistics, sonar, radar, and speech processing, seismology, and others. Spectrograms of audio can be used to identify spoken words phonetically, and to analyse the various calls of animals.
      A spectrogram can be generated by an optical spectrometer, a bank of band-pass filters, by Fourier transform or by a wavelet transform (in which case it is also known as a scaleogram or scalogram).
      <br />
A spectrogram is a visual way of representing the signal strength, or “loudness”, of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.
    </p>
    <img :src="spec_image" />
    <hr>
    <h2>Zero-crossing Rate v/s Signal Energy</h2>
    <p>
      The zero-crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to zero to negative or from negative to zero to positive.[1] This feature has been used heavily in both speech recognition and music information retrieval, being a key feature to classify percussive sounds.
      Zero crossing rates are used for Voice activity detection (VAD), i.e., finding whether human speech is present in an audio segment or not.

    </p>
    <img :src="analyze_image" />
    <hr>
  </div>
</template>

<script>
import axios from "axios";

export default {
  props: ["selectedFile"],
  data() {
    return {
      wave_image: "",
      spec_image: "",
      analyze_image: ""
    };
  },
  mounted() {
    this.get_waveform_images();
  },
  methods: {
    get_waveform_images() {
      axios
        .get("http://localhost:5001/wave_image?filename=" + this.selectedFile, {
          responseType: "blob"
        })
        .then(response => {
          this.wave_image = URL.createObjectURL(response.data);
        })
        .catch(error => {});
      axios
        .get("http://localhost:5001/spec_image?filename=" + this.selectedFile, {
          responseType: "blob"
        })
        .then(response => {
          this.spec_image = URL.createObjectURL(response.data);
        })
        .catch(error => {});
      axios
        .get(
          "http://localhost:5001/analyze_image?filename=" + this.selectedFile,
          { responseType: "blob" }
        )
        .then(response => {
          this.analyze_image = URL.createObjectURL(response.data);
        })
        .catch(error => {});
    }
  }
};
</script>

<style>
img {
  width: 80%;
}
</style>